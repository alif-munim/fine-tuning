{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ebaf0a-288b-486d-aa93-d0423bdd7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install sklearn\n",
    "!{sys.executable} -m pip install -U transformers==4.30.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20913a03-9c67-412a-b170-e4af0609db8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1b7f5f43-2d23-432c-85fa-3c162e558e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_paths = ['', '/cvmfs/soft.computecanada.ca/easybuild/python/site-packages', '/cvmfs/soft.computecanada.ca/custom/python/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python310.zip', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/lib-dynload', '/home/alif/.local/lib/python3.10/site-packages', '/scratch/alif/peft/src', '/scratch/alif/lm-evaluation-harness', '/scratch/alif/minOFT', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Compiler/gcc9/opencv/4.8.0/lib/python3.10/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023b/lib/python3.10/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/ipykernel/2023b/lib/python3.10/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Compiler/gcc9/arrow/13.0.0/lib/python3.10/site-packages', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Compiler/gcc9/arrow/13.0.0/lib/python3.10/site-packages/pyarrow-13.0.0-py3.10-linux-x86_64.egg', '/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/oldest-supported-numpy/2022a/lib/python3.10/site-packages']\n",
    "# for path in new_paths:\n",
    "#     if path not in sys.path:\n",
    "#         sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f5cf2e7-7328-4f65-9880-e48e705a4a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export JUPYTER_PATH=\"${JUPYTER_PATH}:/path/to/add/here/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "047cec50-9fc5-44e5-b9c6-f59244fd02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/scratch/alif'\n",
    "os.environ['HF_DATASETS_CACHE'] = '/scratch/alif'\n",
    "os.environ['HF_HOME'] = '/scratch/alif'\n",
    "os.environ['WANDB_MODE'] = 'offline'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "986189a5-7c03-4ba3-b080-3bd1ee1927cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53b54c0-abe0-467e-a52e-db0e78d71d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59f9477c-13cf-477c-81de-32b57ae28948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "dataset_name = \"timdettmers/openassistant-guanaco\"\n",
    "\n",
    "lora_r = 64\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "\n",
    "\n",
    "use_4bit = True\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "use_nested_quant = False\n",
    "\n",
    "\n",
    "output_dir = \"./results\"\n",
    "num_train_epochs = 1\n",
    "fp16 = True\n",
    "bf16 = False\n",
    "per_device_train_batch_size = 1\n",
    "per_device_eval_batch_size = 1\n",
    "gradient_accumulation_steps = 1\n",
    "gradient_checkpointing = True\n",
    "max_grad_norm = 0.3\n",
    "learning_rate = 2e-4\n",
    "weight_decay = 0.001\n",
    "\n",
    "\n",
    "optim = \"paged_adamw_32bit\"\n",
    "lr_scheduler_type = \"cosine\"\n",
    "max_steps = -1\n",
    "warmup_ratio = 0.03\n",
    "group_by_length = True\n",
    "\n",
    "save_steps = 0\n",
    "logging_steps = 25\n",
    "\n",
    "\n",
    "max_seq_length = None\n",
    "packing = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c465b4fa-ada3-4598-91df-2bf610048764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0215e619cb7c402eb8ca8632d76f95aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "        fp16 = False\n",
    "        bf16 = True\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    # device_map=device_map,\n",
    "    cache_dir=\"/scratch/alif\"\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "# Load LLaMA tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, cache_dir=\"/scratch/alif\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\" # Fix weird overflow issue with fp16 training\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca31ebd1-7dfe-406d-aef3-7e4aa68c8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/scratch/alif/timdettmers___json/timdettmers--openassistant-guanaco-c93588435bc90172/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e/\"\n",
    "train_path = os.path.join(dataset_path, 'json-train.arrow')\n",
    "test_path = os.path.join(dataset_path, 'json-test.arrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37499103-54e9-4471-a983-61003b54a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_file(train_path)\n",
    "test_dataset = Dataset.from_file(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "845ef8ba-5e8c-4401-bb98-527d2e33d185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '### Human: Can you write a short introduction about the relevance of the term \"monopsony\" in economics? Please use examples related to potential monopsonies in the labour market and cite relevant research.### Assistant: \"Monopsony\" refers to a market structure where there is only one buyer for a particular good or service. In economics, this term is particularly relevant in the labor market, where a monopsony employer has significant power over the wages and working conditions of their employees. The presence of a monopsony can result in lower wages and reduced employment opportunities for workers, as the employer has little incentive to increase wages or provide better working conditions.\\n\\nRecent research has identified potential monopsonies in industries such as retail and fast food, where a few large companies control a significant portion of the market (Bivens & Mishel, 2013). In these industries, workers often face low wages, limited benefits, and reduced bargaining power, leading to a situation where they are dependent on the employer for their livelihood. This dependence can result in further suppression of wages and a decline in working conditions.\\n\\nOverall, the concept of monopsony is essential to understanding the dynamics of labor markets and the impact of market power on workers. Further research is needed to understand the extent and impact of monopsonies on the economy and to develop policies to address this issue.\\n\\nReferences:\\nBivens, J., & Mishel, L. (2013). The Pay of Corporate Executives and Financial Professionals as Evidence of Rents in Top 1 Percent Incomes. Journal of Economic Perspectives, 27(3), 57-78.### Human: Now explain it to a dog'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96ceebb1-8021-40aa-ad1c-9dfc1a6c6ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alif/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  cluster\n",
      "0     ### Human: Can you write a short introduction ...        0\n",
      "1     ### Human: ¿CUales son las etapas del desarrol...        1\n",
      "2     ### Human: Can you explain contrastive learnin...        0\n",
      "3     ### Human: I want to start doing astrophotogra...        0\n",
      "4     ### Human: Método del Perceptrón biclásico: de...        1\n",
      "...                                                 ...      ...\n",
      "9841  ### Human: What are the risks when you do not ...        0\n",
      "9842  ### Human: 为什么不能关灯玩手机？### Assistant: 出於各種原因，不建...        0\n",
      "9843  ### Human: ¿De qué está hecho el plástico?### ...        1\n",
      "9844  ### Human: Nortzuk ziren Harry Potteren guraso...        0\n",
      "9845  ### Human: Nork jarri zion ahotsa Dragoi Bolak...        0\n",
      "\n",
      "[9846 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'train_dataset' is a list of dictionaries with the key 'text'\n",
    "texts = [entry['text'] for entry in train_dataset]\n",
    "\n",
    "# Step 1 & 2: Data Preparation and Feature Extraction\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Step 3: Clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Assigning cluster labels to each text\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Creating a DataFrame for easier visualization\n",
    "clustered_data = pd.DataFrame({'text': texts, 'cluster': cluster_labels})\n",
    "\n",
    "print(clustered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7815f17f-d0bb-46a0-9787-be6bb3d1a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'clustered_data' is your DataFrame with texts and cluster labels\n",
    "\n",
    "# Split the DataFrame into two based on the cluster labels\n",
    "cluster_0_df = clustered_data[clustered_data['cluster'] == 0]\n",
    "cluster_1_df = clustered_data[clustered_data['cluster'] == 1]\n",
    "\n",
    "# Convert these DataFrames into Hugging Face Dataset objects\n",
    "cluster_0_dataset = Dataset.from_pandas(cluster_0_df)\n",
    "cluster_1_dataset = Dataset.from_pandas(cluster_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "486678a7-5c41-4183-999b-682d079f03db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/alif/peft/src/peft/utils/other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "/home/alif/.local/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:159: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0602b97e8e7644649cd92e6b4d71f6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6450 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=None\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=cluster_0_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4aaf2-9e84-4432-a24d-bb1c69424d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/python/3.10.2/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/__main__.py\", line 3, in <module>\n",
      "    cli.cli(prog_name=\"python -m wandb\")\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/click/core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/click/core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/click/core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/click/core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/click/core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/cli/cli.py\", line 106, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/cli/cli.py\", line 291, in service\n",
      "    server.serve()\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/server.py\", line 153, in serve\n",
      "    mux.loop()\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 422, in loop\n",
      "    raise e\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 420, in loop\n",
      "    self._loop()\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 413, in _loop\n",
      "    self._process_action(action)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 375, in _process_action\n",
      "    self._process_add(action)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 229, in _process_add\n",
      "    stream.start_thread(thread)\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 81, in start_thread\n",
      "    self._wait_thread_active()\n",
      "  File \"/home/alif/.local/lib/python3.10/site-packages/wandb/sdk/service/streams.py\", line 86, in _wait_thread_active\n",
      "    assert result\n",
      "AssertionError\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/alif/.local/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='697' max='1613' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 697/1613 32:30 < 42:50, 0.36 it/s, Epoch 0.43/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.545400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1.094700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.393600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>1.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>1.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275</td>\n",
       "      <td>1.187400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.497000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325</td>\n",
       "      <td>1.162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375</td>\n",
       "      <td>1.192400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.476300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425</td>\n",
       "      <td>1.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.459200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475</td>\n",
       "      <td>1.102700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.519600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>1.186100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575</td>\n",
       "      <td>1.194400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>1.133000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675</td>\n",
       "      <td>1.102100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "new_model = \"llama-2-7b-guanaco-cluster0\"\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76ad70-1baa-4a1a-95fe-f96e394aff6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OFT",
   "language": "python",
   "name": "oft_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
